{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Segmentation of Water using U-Net\n",
    "# Part 5 - Training with Data Augmentation\n",
    "\n",
    "\n",
    "In this part I will train a CNN using data augmentation and evaluate the effect of this strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.layers import concatenate, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, save_img\n",
    "import numpy as np\n",
    "import json, os\n",
    "from random import shuffle\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unetlib.preprocessing import get_lakes_with_masks, make_dataframes_for_flow, make_img_msk_flows\n",
    "import unetlib.visualisation as vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imagery directories\n",
    "nwpu_data_dir = 'nwpu_lake_images/data/'\n",
    "nwpu_mask_dir = 'nwpu_lake_images/masks/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Training & Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the test/train data\n",
    "train_img_df, train_msk_df, test_img_df, test_msk_df, = make_dataframes_for_flow(nwpu_data_dir,\n",
    "                                                                                 nwpu_mask_dir,\n",
    "                                                                                 test_size=0.25,\n",
    "                                                                                 random_state=42\n",
    "                                                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 210 validated image filenames.\n",
      "Found 210 validated image filenames.\n",
      "Found 90 validated image filenames.\n",
      "Found 90 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# Split the training data into train and validation generators\n",
    "# with augmentation applied to the training data only\n",
    "aug_dict = {'rotation_range':90,\n",
    "            'horizontal_flip':True,\n",
    "            'vertical_flip':True,\n",
    "            'width_shift_range':0.15,\n",
    "            'height_shift_range':0.15,\n",
    "            'zoom_range':0.25\n",
    "           }\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_gen, val_gen, train_fps, val_fps = make_img_msk_flows(train_img_df, train_msk_df,\n",
    "                                                            nwpu_data_dir, nwpu_mask_dir,\n",
    "                                                            val_split=0.3, rescale=1/255.,\n",
    "                                                            aug_dict=aug_dict,\n",
    "                                                            batch_size=batch_size\n",
    "                                                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unetlib.model import UNet\n",
    "from unetlib.metrics import BinaryMeanIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline_aug\n",
      "Model: \"baseline_aug\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 256, 256, 32) 896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 32) 9248        conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 128, 128, 32) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 64) 18496       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 64) 36928       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 64)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 128)  73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 128)  147584      conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 128, 128, 64) 32832       conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 128, 128, 128 0           conv2d_3[0][0]                   \n",
      "                                                                 conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 128, 128, 64) 73792       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 128, 128, 64) 36928       conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 256, 256, 32) 8224        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256, 256, 64) 0           conv2d_1[0][0]                   \n",
      "                                                                 conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 256, 256, 32) 18464       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 256, 256, 32) 9248        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 256, 256, 1)  33          conv2d_9[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 466,529\n",
      "Trainable params: 466,529\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Same configuration as baseline model from part 3\n",
    "model = UNet(n_filters=32, n_blocks=2, model_name='baseline_aug')\n",
    "print(model.name)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='RMSProp',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[BinaryMeanIoU(threshold=0.5)]\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Steps: 14\n",
      "Val Steps: 6\n"
     ]
    }
   ],
   "source": [
    "# Compute steps per epoch\n",
    "train_steps = int(np.ceil(len(train_fps) / batch_size))\n",
    "val_steps = int(np.ceil(len(val_fps) / batch_size))\n",
    "\n",
    "print(f'Train Steps: {train_steps}')\n",
    "print(f'Val Steps: {val_steps}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of times to cycle the full training set\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model and record the time taken\n",
    "    \n",
    "t1 = time.time()\n",
    "history = model.fit(train_gen, epochs=epochs, steps_per_epoch=train_steps,\n",
    "                    validation_data=val_gen, validation_steps=val_steps)\n",
    "runtime = time.time() - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many minutes did training take?\n",
    "print(runtime / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure model output directory and filenames\n",
    "output_dir = 'model_outputs'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "hist_filepath = os.path.join(output_dir,\n",
    "                             f'{model.name}_bs{batch_size}e{epochs}.history.pickle')\n",
    "\n",
    "weights_filepath = os.path.join(output_dir,\n",
    "                                f'{model.name}_bs{batch_size}e{epochs}.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save history to pickle\n",
    "with open(hist_filepath, 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "    \n",
    "# Save model weights\n",
    "model.save_weights(weights_filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
